INFO:     Will watch for changes in these directories: ['/home/test_code/test01/rag-chatbot/backend']
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
INFO:     Started reloader process [4015424] using WatchFiles
/home/test_code/test01/rag-chatbot/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
NoneType: None
2025-05-18 20:04:56,679 - elastic_transport.transport - INFO - HEAD http://172.10.2.70:9200/ [status:200 duration:0.001s]
2025-05-18 20:04:56,680 - elastic_transport.transport - INFO - HEAD http://172.10.2.70:9200/rag_documents_kure_v1 [status:200 duration:0.000s]
2025-05-18 20:04:56,685 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: /home/root/kpf-sbert-v1.1
2025-05-18 20:04:57,283 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Initializing Elasticsearch client...
Elasticsearch client connected successfully.
Loading embedding function...
임베딩 모델 로드 성공: /home/root/kpf-sbert-v1.1
Loading LLM model and tokenizer...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]
2025-05-18 20:05:02,756 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
LLM model loaded successfully with Flash Attention.
GPU 메모리 사용량: 5.62 GB
Loading reranker model...
Reranker model loaded successfully.
SQLCoder 모델 로딩 중...
SQLCoder 모델 로드 시작: /home/root/llama-3-sqlcoder-8b
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.24s/it]
/home/test_code/test01/rag-chatbot/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test_code/test01/rag-chatbot/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
INFO:     Started server process [4015428]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Stopping reloader process [4015424]
/root/.pyenv/versions/3.10.14/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
